{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mustafabozkaya/Deep_Learning_Bootcamp/blob/master/AI/ML%20Challenge/manually_tuned_densenet201_binary_eye_classification2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYRtpk3xGAeS"
      },
      "source": [
        "**Name : Mustafa Bozkaya**\n",
        "\n",
        "Binary prediction of image: male eye or female eye. Using DenseNet201."
      ],
      "id": "TYRtpk3xGAeS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV75FK1nLaGe"
      },
      "source": [
        "**Download the images**"
      ],
      "id": "AV75FK1nLaGe"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive/',force_remount=True)"
      ],
      "metadata": {
        "id": "3MgfpOgYxSL2",
        "outputId": "eec2e01d-b0d2-4e5a-c773-c9ffd5249a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3MgfpOgYxSL2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mydrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "tEMc8rsDx_ex",
        "outputId": "b246ae1a-1148-4d0a-88b4-4c3fb14dc51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "tEMc8rsDx_ex",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip \"/content/mydrive/MyDrive/eye_gender_data.zip\" -d \"/content/datasets/\""
      ],
      "metadata": {
        "id": "--whdSJ3yB5J"
      },
      "id": "--whdSJ3yB5J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CJJufhhLoU9"
      },
      "source": [
        "**Summary of Libraries**"
      ],
      "id": "2CJJufhhLoU9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPLbUd5xLqiy"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.applications import mobilenet_v2, Xception, NASNetLarge, NASNetMobile, DenseNet201, InceptionResNetV2\n",
        "from google.colab import files\n",
        "from keras import backend as K"
      ],
      "id": "qPLbUd5xLqiy",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"]=(18,8)\n",
        "%matplotlib inline\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "h-uKtxoa0PmI"
      },
      "id": "h-uKtxoa0PmI",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpZ-6pDeMnem"
      },
      "source": [
        "**Loading data**"
      ],
      "id": "lpZ-6pDeMnem"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAL7r95L4kny"
      },
      "source": [
        "# import zipfile, os\n",
        "# local_zip = '/content/eye_gender_data.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('/content')\n",
        "# zip_ref.close()"
      ],
      "id": "WAL7r95L4kny",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = pd.read_csv(\"/content/datasets/eye_gender_data/Training_set.csv\") \n",
        "test_labels = pd.read_csv(\"/content/datasets/eye_gender_data/Testing_set.csv\") \n",
        "submission= pd.read_csv(\"/content/datasets/eye_gender_data/sample_submission.csv\") "
      ],
      "metadata": {
        "id": "X3I7DzJ5y795"
      },
      "id": "X3I7DzJ5y795",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba9d2856"
      },
      "source": [
        "train_dataset_dir=f\"/content/datasets/eye_gender_data/train\""
      ],
      "id": "ba9d2856",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c801531"
      },
      "source": [
        "# Pinned this for trial-error someday, maybe\n",
        "# for i in os.listdir(train_dataset_dir):\n",
        "#     print(i)"
      ],
      "id": "1c801531",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(train_dataset_dir)\n",
        "image_count = len(list(data_dir.glob('*_*.jpg')))\n",
        "print(image_count)\n"
      ],
      "metadata": {
        "id": "FtIjwpFK0f4q",
        "outputId": "4f54d75a-9878-48b5-bdd7-8858a23d5672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FtIjwpFK0f4q",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spec = list(data_dir.glob('*.jpg'))\n",
        "img=PIL.Image.open(str(spec[9])).resize((128,128))\n",
        "img"
      ],
      "metadata": {
        "id": "PM8zALUt0h_y",
        "outputId": "f128da1b-b7cf-45dc-a435-643dbe24a051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "id": "PM8zALUt0h_y",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F62235682D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgarr=np.array(img)\n",
        "imgarr.shape"
      ],
      "metadata": {
        "id": "YdVFWfgp0x_f",
        "outputId": "be1ca99a-5e05-46b2-f127-c34ca3bdbc15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YdVFWfgp0x_f",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cptxOQroTOh9"
      },
      "source": [
        "**Loading and preparing test data**"
      ],
      "id": "cptxOQroTOh9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CHncKa2srOO"
      },
      "source": [
        "If using imagedatagenerator, photo is sorted alphabetically\n",
        "\n",
        "Test list requirement in Testing_set.csv is sorted ascending, but not alphabetically\n",
        "\n",
        "So the way to prepare photos is either sort test image alphabetically or loop predict based on test's csv"
      ],
      "id": "4CHncKa2srOO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IzInbKh-yvF"
      },
      "source": [
        "test_path = train_dataset_d=f\"/content/datasets/eye_gender_data/test/\"\n",
        "\n",
        "for i in os.listdir(test_path):\n",
        "  c = 14-len(i)\n",
        "  os.rename(test_path + i, test_path + i[:6] + '0'*c + i[6:])"
      ],
      "id": "2IzInbKh-yvF",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk1y5URtU3-V"
      },
      "source": [
        "**Loading and preparing training data**"
      ],
      "id": "jk1y5URtU3-V"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e29f4afd"
      },
      "source": [
        "train_labels = pd.read_csv(\"/content/datasets/eye_gender_data/Training_set.csv\") \n",
        "test_labels = pd.read_csv(\"/content/datasets/eye_gender_data/Testing_set.csv\") \n",
        "submission= pd.read_csv(\"/content/datasets/eye_gender_data/sample_submission.csv\") "
      ],
      "id": "e29f4afd",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2b5a586d",
        "outputId": "0e3baf16-28ab-4b56-92fb-aeaec56bec33"
      },
      "source": [
        "train_labels.head()"
      ],
      "id": "2b5a586d",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      filename   label\n",
              "0  Image_1.jpg    male\n",
              "1  Image_2.jpg  female\n",
              "2  Image_3.jpg  female\n",
              "3  Image_4.jpg  female\n",
              "4  Image_5.jpg    male"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff4ef16d-a51c-4c5b-a01f-563e48cfae6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff4ef16d-a51c-4c5b-a01f-563e48cfae6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff4ef16d-a51c-4c5b-a01f-563e48cfae6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff4ef16d-a51c-4c5b-a01f-563e48cfae6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.head()"
      ],
      "metadata": {
        "id": "2tgtI5Vo2EHy",
        "outputId": "6004216d-da9b-4673-fb06-890a6aeda07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "id": "2tgtI5Vo2EHy",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      filename\n",
              "0  Image_1.jpg\n",
              "1  Image_2.jpg\n",
              "2  Image_3.jpg\n",
              "3  Image_4.jpg\n",
              "4  Image_5.jpg"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1b0248a-b6e3-46c9-9581-f08152d89790\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1b0248a-b6e3-46c9-9581-f08152d89790')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1b0248a-b6e3-46c9-9581-f08152d89790 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1b0248a-b6e3-46c9-9581-f08152d89790');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "764d8199"
      },
      "source": [
        "female_path = img_path + 'female/'\n",
        "male_path = img_path + 'male/'"
      ],
      "id": "764d8199",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f5ba78d"
      },
      "source": [
        "# Prepare to use imagedatagenerator: create two folder, male and female and distribute correctly based on Training_set.csv\n",
        "if not os.path.exists(female_path):\n",
        "    os.makedirs(female_path)\n",
        "if not os.path.exists(male_path):\n",
        "    os.makedirs(male_path)\n",
        "\n",
        "for i,j in zip(d.filename, d.label): \n",
        "    try:\n",
        "        os.rename(img_path + i, img_path + j + '/' + i)\n",
        "    except:\n",
        "        pass"
      ],
      "id": "4f5ba78d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eaf0add",
        "outputId": "3c13d0ec-763e-492b-8bba-43fd98ba351d"
      },
      "source": [
        "# A simple distribution check\n",
        "len(os.listdir(male_path))"
      ],
      "id": "8eaf0add",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5058"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8397cc3",
        "outputId": "707d57bd-7044-47a0-8fae-09533d4da84b"
      },
      "source": [
        "len(os.listdir(female_path))"
      ],
      "id": "d8397cc3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4162"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e03bea71"
      },
      "source": [
        "z=len(os.listdir(img_path))"
      ],
      "id": "e03bea71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZAj0Iu5StuY"
      },
      "source": [
        "# Apply class weight to the model later\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_array = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(d.label.values),\n",
        "    y=d.label.values)\n",
        "\n",
        "class_weights = dict(enumerate(class_array))"
      ],
      "id": "0ZAj0Iu5StuY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF3hk6Wlzks7",
        "outputId": "82e245da-4f8f-42a8-d273-de9b21809a0d"
      },
      "source": [
        "# 0 is female. Since female class is lesser than male, female class get weighted more\n",
        "class_weights"
      ],
      "id": "sF3hk6Wlzks7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.1076405574243153, 1: 0.911427441676552}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGeClMTUz1IA",
        "outputId": "2cbe0246-3891-4315-fe87-73adec0de9eb"
      },
      "source": [
        "class_array"
      ],
      "id": "jGeClMTUz1IA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.10764056, 0.91142744])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAE1lRyMRo7n"
      },
      "source": [
        "**Data Pre-processing (on train, validation and test data)**"
      ],
      "id": "nAE1lRyMRo7n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf8a6b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e27475-fc90-4663-8607-d0f22fce7590"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# import random\n",
        "# random_number = random.randint(0, 100)\n",
        "# print(random_number)\n",
        "\n",
        "# import numpy as np\n",
        "# np.random.seed(82)\n",
        "\n",
        "# set_seed = random_number\n",
        "set_seed = 82\n",
        "target_img = (75,75) # Not the smallest but not the largest pixel in the data\n",
        "batch = 256\n",
        "# val_split = 0.02501\n",
        "val_split = 0.0502 # Set fraction fold (here 461 validation image, 20% of test data)\n",
        "\n",
        "# def grayscale_as_rgb_dim(img):\n",
        "#     img = tf.image.rgb_to_grayscale(img)\n",
        "#     img = tf.image.grayscale_to_rgb(img)\n",
        "#     return img\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.,\n",
        "    # preprocessing_function=grayscale_as_rgb_dim,\n",
        "                    \n",
        "    # featurewise_center=False,\n",
        "    # samplewise_center=False,\n",
        "    # featurewise_std_normalization=False,\n",
        "    # samplewise_std_normalization=False,\n",
        "    )\n",
        "\n",
        "folder_path='eye_gender_data/'\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    folder_path,\n",
        "    # only read images from test directory\n",
        "    classes=['test'],\n",
        "    # color_mode='grayscale',\n",
        "    # don't generate labels\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    target_size=target_img\n",
        "    )\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1/255,\n",
        "    rotation_range=10,\n",
        "    horizontal_flip=True,\n",
        "    # vertical_flip=True,\n",
        "    width_shift_range=0.125,\n",
        "    height_shift_range=[-0.15, 0.05],\n",
        "    # shear_range = 0.2,\n",
        "    zoom_range=0.1,\n",
        "    # brightness_range=[0.9,1.0],\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split=val_split,\n",
        "    # preprocessing_function=grayscale_as_rgb_dim,\n",
        "\n",
        "    # featurewise_center=False,\n",
        "    # samplewise_center=False,\n",
        "    # featurewise_std_normalization=False,\n",
        "    # samplewise_std_normalization=False,\n",
        "    )\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    img_path,\n",
        "    target_size=target_img,\n",
        "    # color_mode='grayscale',\n",
        "    batch_size=batch,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    seed=set_seed\n",
        "    )\n",
        "\n",
        "datagenval = ImageDataGenerator(\n",
        "    rescale=1/255,\n",
        "    validation_split=val_split,\n",
        "    # preprocessing_function=grayscale_as_rgb_dim,\n",
        "    \n",
        "    # featurewise_center=False,\n",
        "    # samplewise_center=False,\n",
        "    # featurewise_std_normalization=False,\n",
        "    # samplewise_std_normalization=False,\n",
        "    )\n",
        "\n",
        "validation_generator = datagenval.flow_from_directory(\n",
        "    img_path,\n",
        "    target_size=target_img,\n",
        "    # color_mode='grayscale',\n",
        "    batch_size=batch,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    seed=set_seed\n",
        "    )"
      ],
      "id": "bf8a6b0d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2305 images belonging to 1 classes.\n",
            "Found 8759 images belonging to 2 classes.\n",
            "Found 461 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RExzYWPRR39k"
      },
      "source": [
        "**Building Model & Hyperparameter tuning (Manually)**"
      ],
      "id": "RExzYWPRR39k"
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "marked": false
        },
        "id": "ff5ed814"
      },
      "source": [
        "from tensorflow.keras.applications import mobilenet_v2, Xception, NASNetLarge, NASNetMobile, DenseNet201, InceptionResNetV2\n",
        "\n",
        "tf.random.set_seed(set_seed)\n",
        "model = tf.keras.models.Sequential([\n",
        "#   tf.keras.layers.InputLayer((*target_img,3)),\n",
        "#   tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
        "#   tf.keras.layers.BatchNormalization(),\n",
        "#   tf.keras.layers.MaxPooling2D(2, 2),\n",
        "# #   # tf.keras.layers.Dropout(0.9),\n",
        "#   tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "#   tf.keras.layers.BatchNormalization(),\n",
        "#   tf.keras.layers.MaxPooling2D(2,2),\n",
        "# #   tf.keras.layers.Dropout(0.9),\n",
        "#   tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "#   tf.keras.layers.BatchNormalization(),\n",
        "#   tf.keras.layers.MaxPooling2D(2,2),\n",
        "# #   tf.keras.layers.Dropout(0.9),\n",
        "#   tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "#   tf.keras.layers.BatchNormalization(),\n",
        "#   tf.keras.layers.MaxPooling2D(2,2),\n",
        "# #   tf.keras.layers.Dropout(0.9),\n",
        "#   tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "#   tf.keras.layers.BatchNormalization(),\n",
        "#   tf.keras.layers.MaxPooling2D(2,2),\n",
        "#   # tf.keras.layers.Dropout(0.9),\n",
        "#   tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
        "#   tf.keras.layers.BatchNormalization(),\n",
        "#   tf.keras.layers.MaxPooling2D(2,2),\n",
        "#   # tf.keras.layers.Dropout(0.9),\n",
        "    \n",
        "#   tf.keras.layers.Conv2D(1024, (3,3), activation='relu', padding='same'),\n",
        "#   tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "  # InceptionResNetV2(weights=\"imagenet\", include_top=False, input_shape=(*target_img,3)), # Minimal must 75x75 \n",
        "  DenseNet201(weights=\"imagenet\", include_top=False, input_shape=(*target_img,3)),\n",
        "  # NASNetMobile(weights=\"imagenet\", include_top=False, input_shape=(*target_img,3)), # Must 224x224\n",
        "  # NASNetLarge(weights=\"imagenet\", include_top=False, input_shape=(*target_img,3)), # Must 224x224\n",
        "  # Xception(weights=\"imagenet\", include_top=False, input_shape=(*target_img,3)), # Minimal must 71x71 \n",
        "  # mobilenet_v2.MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(*target_img,3)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  # tf.keras.layers.Dropout(0.95),\n",
        "#   tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(z-1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# model.layers[0].trainable = True"
      ],
      "id": "ff5ed814",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks8DFQmIv4u2"
      },
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=5e-2),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "id": "Ks8DFQmIv4u2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa337850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4151474a-94f5-400f-f993-95c2d5dcfc02"
      },
      "source": [
        "model.summary()"
      ],
      "id": "aa337850",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet201 (Functional)     (None, 2, 2, 1920)        18321984  \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 2, 2, 1920)        7680      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 7680)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               3932672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 22,264,897\n",
            "Trainable params: 22,030,977\n",
            "Non-trainable params: 233,920\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8795705"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('val_accuracy')==1):\n",
        "            print(\"\\nMaximum Validtion Accuracy has reached!\")\n",
        "            self.model.stop_training = True\n",
        "callback = myCallback()\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    'model5.h5',\n",
        "    monitor = 'val_accuracy',\n",
        "    save_best_only = True,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#     monitor = 'val_accuracy',\n",
        "#     patience = 15,\n",
        "#     factor = 0.02,\n",
        "#     min_lr = 1e-5,\n",
        "#     # cooldown = 5,\n",
        "#     verbose = 1\n",
        "# )\n",
        "\n",
        "set_callback = [\n",
        "  checkpoint, \n",
        "  # reduce_lr,\n",
        "  # callback,\n",
        "  # early\n",
        "]"
      ],
      "id": "c8795705",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmAvV7ZjWVto"
      },
      "source": [
        "**Load model**"
      ],
      "id": "gmAvV7ZjWVto"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjWcCQjPS1Qi"
      },
      "source": [
        "# model.load_weights('model5.h5')\n",
        "# model.load_weights('check9.h5')\n",
        "# print(K.eval(model.optimizer.lr)) # Print learning rate of model"
      ],
      "id": "jjWcCQjPS1Qi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqGecTqwWbCT"
      },
      "source": [
        "**Change learning rate amid fit**"
      ],
      "id": "OqGecTqwWbCT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjQL8y2Ga3m3"
      },
      "source": [
        "# How to use: set smaller when we feel the fit begin to falls on the right minima (global)\n",
        "\n",
        "# K.set_value(model.optimizer.learning_rate, 1e-3) # Set new learning rate for model\n",
        "# print(K.eval(model.optimizer.lr))"
      ],
      "id": "qjQL8y2Ga3m3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM9CT44ZTAm7"
      },
      "source": [
        "**Validate the model**"
      ],
      "id": "tM9CT44ZTAm7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB9DpII542ad"
      },
      "source": [
        "Usually I manually run and stop amid the fit like this. This actually has been going to more than 100 epoch."
      ],
      "id": "tB9DpII542ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVWMwK4jVyde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf8bbb19-e0c8-42ac-99c5-935a9c9c136e"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs = 30,\n",
        "      validation_data=validation_generator,\n",
        "      callbacks=[set_callback],\n",
        "      class_weight=class_weights,\n",
        "      verbose = 1\n",
        "      )"
      ],
      "id": "NVWMwK4jVyde",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "35/35 [==============================] - 23s 655ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1111 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98698\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - 24s 684ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0942 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.98698\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - 23s 656ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1334 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.98698\n",
            "Epoch 4/50\n",
            "35/35 [==============================] - 24s 663ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1160 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.98698\n",
            "Epoch 5/50\n",
            "35/35 [==============================] - 24s 683ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1298 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.98698\n",
            "Epoch 6/50\n",
            "35/35 [==============================] - 23s 650ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.1061 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.98698\n",
            "Epoch 7/50\n",
            "35/35 [==============================] - 24s 684ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.1168 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.98698\n",
            "Epoch 8/50\n",
            "35/35 [==============================] - 24s 662ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1077 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.98698\n",
            "Epoch 9/50\n",
            "35/35 [==============================] - 23s 654ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.1490 - val_accuracy: 0.9653\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.98698\n",
            "Epoch 10/50\n",
            "35/35 [==============================] - 23s 660ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0999 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.98698\n",
            "Epoch 11/50\n",
            "35/35 [==============================] - 23s 651ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0941 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.98698\n",
            "Epoch 12/50\n",
            "35/35 [==============================] - 24s 662ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0870 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.98698\n",
            "Epoch 13/50\n",
            "35/35 [==============================] - 24s 671ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0904 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.98698\n",
            "Epoch 14/50\n",
            "35/35 [==============================] - 23s 639ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0973 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.98698\n",
            "Epoch 15/50\n",
            "35/35 [==============================] - 24s 664ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1045 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.98698\n",
            "Epoch 16/50\n",
            "35/35 [==============================] - 23s 638ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0878 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.98698\n",
            "Epoch 17/50\n",
            "35/35 [==============================] - 24s 683ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1476 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.98698\n",
            "Epoch 18/50\n",
            "35/35 [==============================] - 24s 677ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1147 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.98698\n",
            "Epoch 19/50\n",
            "35/35 [==============================] - 23s 648ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.1000 - val_accuracy: 0.9761\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.98698\n",
            "Epoch 20/50\n",
            "35/35 [==============================] - 24s 673ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0944 - val_accuracy: 0.9805\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.98698\n",
            "Epoch 21/50\n",
            "35/35 [==============================] - 23s 648ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1423 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.98698\n",
            "Epoch 22/50\n",
            "35/35 [==============================] - 24s 670ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1339 - val_accuracy: 0.9783\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.98698\n",
            "Epoch 23/50\n",
            " 5/35 [===>..........................] - ETA: 19s - loss: 0.0036 - accuracy: 0.9984"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-247-852b7ede6b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOogOAV5sb9L"
      },
      "source": [
        "Using GPU we will never get the same result. Actually all the seed here is futile (except imagedatagenerator seed)\n",
        "\n",
        "So in competition, when we get a good result in submission, don't forget to save\n",
        "\n",
        "Then we can load it (architecture must be same, some imagedatagenerator properties must same)\n",
        "\n",
        "Actually we can do without model.fit at first at all"
      ],
      "id": "IOogOAV5sb9L"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnaVeaKOSOvU"
      },
      "source": [
        "**Make Prediction on Test Dataset and Save**"
      ],
      "id": "BnaVeaKOSOvU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FhR0l1YwF8T"
      },
      "source": [
        "preds = model.predict(test_generator)\n",
        "preds;"
      ],
      "id": "4FhR0l1YwF8T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUdjRK9vmiBG"
      },
      "source": [
        "a=preds.round()\n",
        "a=pd.DataFrame(a, columns=['label'])\n",
        "a.label=a.label.map(lambda x: 'female' if x==0 else 'male')\n",
        "a.to_csv('first.csv', index=False)\n",
        "a;"
      ],
      "id": "AUdjRK9vmiBG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD9BRG-LoA0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "89701138-6753-46ed-c6a6-eae2ee839da4"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('first.csv') "
      ],
      "id": "TD9BRG-LoA0V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d8636320-ed68-49ac-8696-3166cf592d92\", \"first.csv\", 13511)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6-c7Q0SlgC7"
      },
      "source": [
        "# If manually tune, maybe we want to stop amid epoch process and want to check validation accuracy\n",
        "model.evaluate(validation_generator)"
      ],
      "id": "O6-c7Q0SlgC7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXP0nOiOWNn7"
      },
      "source": [
        "**Save model and/or download locally**"
      ],
      "id": "rXP0nOiOWNn7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV07c6j1R8N0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5bf2ecd8-ea0b-43b4-8894-51833926d5fb"
      },
      "source": [
        "# model.save('check9.h5')\n",
        "# files.download('check9.h5') "
      ],
      "id": "SV07c6j1R8N0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_933983b3-b4ec-4d0b-ba8f-73d6c077d8d0\", \"check9.h5\", 121724208)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBIHtyi0FSl-"
      },
      "source": [
        "# files.download('model5.h5') "
      ],
      "id": "RBIHtyi0FSl-",
      "execution_count": null,
      "outputs": []
    }
  ]
}